# DUET-Screen

**DTI-docking Unified Evaluation Toolkit for Screening** (DUET-Screen) is a reproducible, scriptable pipeline that simulates a typical drug–target-interaction workflow: scoring molecular pairs, performing docking/MM/GBSA stubs, fusing the results, and exporting ranked hits. The repository bundles helper tooling to prepare ligand libraries from public ZINC dumps, generate configuration files, execute every stage, and summarise results in both JSON and Excel formats.

---

## 1. Requirements

- Ubuntu 20.04/22.04 (or any Linux with Python ≥ 3.9)
- `git`, `python3`, `python3-venv`, `pip`
- Optional but recommended:
  - `aria2c` (bulk HTTP downloads from ZINC)
  - `rsync` (ZINC rsync endpoint)

```bash
sudo apt update
sudo apt install -y git python3 python3-venv python3-pip aria2 rsync
```

---

## 2. Installation (fresh machine)

```bash
# 1) Clone the repository
git clone https://github.com/<your-org>/duet_screen.git
cd duet_screen

# 2) Create and activate a virtual environment (recommended)
python3 -m venv .venv
source .venv/bin/activate

# 3) Upgrade pip and install the project + extras
pip install --upgrade pip
pip install .[zinc,report]

# 4) (Optional) run the unit tests
pytest
```

The `zinc` extra pulls in `requests` for download scripts, and the `report` extra installs `openpyxl` for Excel exports.

---

## 3. Quick Start (built-in toy dataset)

Use the sample ligand/protein data shipped with the repo to validate the installation.

```bash
# Generate a minimal config that references data/sample_ligands.csv
python scripts/create_config.py \
  --output configs/config.sample.json \
  --ligands-file ../data/sample_ligands.csv \
  --chunk-size 10 --dti-top-k 3 --docking-top-k 3 --mmgbsa-top-k 3 \
  --workdir ../workspace_sample

# Execute every pipeline stage and export JSON/XLSX reports
python scripts/run_pipeline.py \
  --config configs/config.sample.json \
  --devices 0 \
  --export-json workspace_sample/reports/pipeline_export.json \
  --export-xlsx workspace_sample/reports/pipeline_export.xlsx \
  --ligand-library data/sample_ligands.csv

# Inspect results
cat workspace_sample/reports/pipeline_export.json
```

This run completes in seconds on any recent machine and confirms the environment is ready.

---

## 4. Preparing a Ligand Library from ZINC

1. **Download SMILES tranches** (bulk HTTP via `aria2c`, rsync, or manual download). Tranches are conventionally stored under `zinc_db/zinc2d_purchasable_smiles`. Example aria2c invocation:

   ```bash
   mkdir -p zinc_db/zinc2d_purchasable_smiles
   aria2c -i urls_purchasable_smi.txt -d zinc_db/zinc2d_purchasable_smiles -c \
          --auto-save-interval=30 --max-tries=20 --retry-wait=15
   ```

   The file `zinc_db/missing_purchasable_smi.txt` (generated by helper scripts) lists any SMILES files that failed to download so you can re-run aria2c until the list is empty.

2. **Convert `.smi` files to a pipeline-ready CSV** using the builder script. You can either convert the entire set or draw a random sample:

   ```bash
   # Full conversion (may be very large!)
   PYTHONPATH=. python scripts/build_ligand_library_from_smi.py \
       --input-dir zinc_db/zinc2d_purchasable_smiles \
       --output zinc_db/purchasable_ligands_full.csv \
       --skip-missing

   # Random 100k sample (reproducible seed)
   PYTHONPATH=. python scripts/build_ligand_library_from_smi.py \
       --input-dir zinc_db/zinc2d_purchasable_smiles \
       --output zinc_db/purchasable_ligands_100k_random.csv \
       --skip-missing --limit 100000 --random-sample --seed 12345
   ```

3. **Create a configuration file** referencing the CSV:

   ```bash
   python scripts/create_config.py \
     --output configs/config.zinc_random100k.json \
     --ligands-file ../zinc_db/purchasable_ligands_100k_random.csv \
     --chunk-size 1000 --dti-top-k 20 --docking-top-k 20 --mmgbsa-top-k 20 \
     --workdir ../workspace_zinc100k
   ```

---

## 5. Running the Full Pipeline

`scripts/run_pipeline.py` can optionally sample the ligands before orchestrating every stage, then export JSON/XLSX summaries. The script prints start/end timestamps and durations for each step.

### Example: 100k-ligand sweep (automatic sampling)

```bash
python scripts/run_pipeline.py \
  --config configs/config.zinc_random100k.json \
  --devices 0 \
  --smi-dir zinc_db/zinc2d_purchasable_smiles \
  --sample-size 100000 \
  --sample-output zinc_db/purchasable_ligands_100k_random.csv \
  --sample-seed 1234 \
  --export-json workspace_zinc100k/reports/pipeline_export.json \
  --export-xlsx workspace_zinc100k/reports/pipeline_export.xlsx
```

### Example: 1M-ligand sweep (be mindful of runtime and disk usage)

```bash
python scripts/run_pipeline.py \
  --config configs/config.zinc_random1M.json \
  --devices 0 \
  --smi-dir zinc_db/zinc2d_purchasable_smiles \
  --sample-size 1000000 \
  --sample-output zinc_db/purchasable_ligands_1M_random.csv \
  --sample-seed 20251030 \
  --export-json workspace_zinc1M/reports/pipeline_export.json \
  --export-xlsx workspace_zinc1M/reports/pipeline_export.xlsx
```

### Understanding the exported reports

Each worksheet in the Excel file (and the corresponding JSON arrays) lists the top-ranked partners for a given input. Columns have the following meaning:

| Column | Meaning |
| ------ | ------- |
| `rank` | 1-based consensus position (1 = best). |
| `partner_id` | Identifier of the candidate ligand or protein. |
| `partner_type` | `ligand` or `protein`. |
| `value` | SMILES string (for ligands) or sequence (for proteins) pulled from the supplied library file. |
| `consensus_score` | Weighted reciprocal rank fusion (WRRF) score used for global ranking. Higher is better. |
| `dti_score`, `docking_score`, `mmgbsa_score` | Deterministic stage scores that fed into the consensus; may be `null` if a stage did not emit the partner. |
| `stages_present` | Comma-separated list of stages that produced non-null scores. |
| `stage_count` | Number of contributing stages. |
| `stage_mean`, `stage_min`, `stage_max`, `stage_std` | Descriptive statistics computed over the available stage scores. |

These fields help diagnose which parts of the pipeline support a candidate and whether it only appeared in a subset of stages.

Outputs appear under the chosen `workdir` (e.g., `workspace_zinc100k/aggregate/final_rankings.json`, `workspace_zinc100k/reports/report.txt`, etc.).

---

## 6. Tool Summary

| Script | Purpose |
| ------ | ------- |
| `scripts/create_config.py` | Generate JSON/YAML configs without manual editing. |
| `scripts/run_pipeline.py` | Full pipeline executor (optional sampling + export). |
| `scripts/build_ligand_library_from_smi.py` | Convert `.smi` tranches to CSV; supports random sampling. |
| `scripts/export_results.py` | Reformat aggregate results to JSON/XLSX, including SMILES/sequence fields and stage statistics. |
| `scripts/fetch_zinc_ligands.py` | Direct HTTP fetch from ZINC (simple queries). |
| `scripts/download_zinc_purchasable.py`, `scripts/download_zinc_tranche.sh` | Batch downloads via curated lists or rsync. |

---

## 7. Troubleshooting

- **Missing PyYAML / openpyxl:** ensure `pip install .[zinc,report]` succeeded inside the virtual environment.  Re-run the command if necessary.
- **aria2c SSL handshake errors:** rerun downloads; ZINC occasionally throttles concurrent connections. Reduce `--max-concurrent-downloads` or add `--max-tries`/`--retry-wait`.
- **Large runs stalled:** the bundled scoring is CPU-bound by design; use manageable `--sample-size` values (100k/250k) or shard runs.  Monitor output timestamps for progress.
- **Config path issues:** `run_pipeline.py` resolves paths relative to the config file. If you override `--workdir` or pass `--sample-output`, ensure those directories exist or are writable.
- **Excel export errors:** confirm `openpyxl` is installed; re-run `pip install .[report]` if missing.

---

## 8. Repository Layout (key directories)

- `duet_screen/` – core package containing config parsing, scheduler, and stage implementations.
- `scripts/` – helper tooling (sampling, download, pipeline orchestration, reporting, config creation).
- `configs/` – ready-made examples, plus user-generated configs.
- `data/` – toy datasets for quick verification.
- `tests/` – pytest suite covering consensus math, scheduler retries, and an end-to-end stub.
- `workspace*/` – pipeline outputs (created on demand).
- `zinc_db/` – recommended location for downloaded ZINC SMILES and generated ligand libraries.

---

With these steps, even a new Ubuntu machine can set up DUET-Screen, harvest ligands from ZINC, execute the full simulated pipeline, and inspect ranked CRBN binders within minutes. Happy screening!
